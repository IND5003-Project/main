{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "\u001b[K    100% |████████████████████████████████| 645kB 17.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: nltk>=3.1 in /anaconda3/lib/python3.7/site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
=======
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
<<<<<<< HEAD
      "[nltk_data]     /Users/abz/nltk_data...\n"
=======
      "[nltk_data]     C:\\Users\\Raphael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\Raphael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\sentiwordnet.zip.\n"
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
<<<<<<< HEAD
     "execution_count": 5,
=======
     "execution_count": 145,
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "import html\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import csv\n",
    "import time\n",
    "\n",
<<<<<<< HEAD
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='neg', p_pos=0.462121212121212, p_neg=0.537878787878788)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"test test\", analyzer=NaiveBayesAnalyzer()).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = './Data/Stocktwit Raw_preprocessed.csv'\n",
    "file_location_raw = './Data/Stocktwit Raw.csv'"
=======
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')"
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 121,
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with pre-labelled existing data from Twitter\n",
    "raw = pd.read_csv('./Data/twitter_corpus-master/full-corpus.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 122,
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
<<<<<<< HEAD
       "      <td>nothing can get this over . Maybe buyout will...</td>\n",
       "      <td>Sep 17th, 8:40 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Aug Calls] up + . Alerted at on Aug : AM Pea...</td>\n",
       "      <td>Sep 17th, 8:28 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peak profit for the last expired option alerts...</td>\n",
       "      <td>Sep 17th, 8:26 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last six months, option alerts peaked above p...</td>\n",
       "      <td>Sep 17th, 8:25 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>down. Not looking good for Tuesday. Fed will ...</td>\n",
       "      <td>Sep 17th, 8:11 am</td>\n",
=======
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126404574230740992</td>\n",
       "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126395626979196928</td>\n",
       "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
<<<<<<< HEAD
       "                                             message           datetime\n",
       "0   nothing can get this over . Maybe buyout will...  Sep 17th, 8:40 am\n",
       "1   [Aug Calls] up + . Alerted at on Aug : AM Pea...  Sep 17th, 8:28 am\n",
       "2  Peak profit for the last expired option alerts...  Sep 17th, 8:26 am\n",
       "3   Last six months, option alerts peaked above p...  Sep 17th, 8:25 am\n",
       "4   down. Not looking good for Tuesday. Fed will ...  Sep 17th, 8:11 am"
      ]
     },
     "execution_count": 14,
=======
       "   Topic Sentiment             TweetId                       TweetDate  \\\n",
       "0  apple  positive  126415614616154112  Tue Oct 18 21:53:25 +0000 2011   \n",
       "1  apple  positive  126404574230740992  Tue Oct 18 21:09:33 +0000 2011   \n",
       "2  apple  positive  126402758403305474  Tue Oct 18 21:02:20 +0000 2011   \n",
       "3  apple  positive  126397179614068736  Tue Oct 18 20:40:10 +0000 2011   \n",
       "4  apple  positive  126395626979196928  Tue Oct 18 20:34:00 +0000 2011   \n",
       "\n",
       "                                           TweetText  \n",
       "0  Now all @Apple has to do is get swype on the i...  \n",
       "1  @Apple will be adding more carrier support to ...  \n",
       "2  Hilarious @youtube video - guy does a duet wit...  \n",
       "3  @RIM you made it too easy for me to switch to ...  \n",
       "4  I just realized that the reason I got into twi...  "
      ]
     },
     "execution_count": 122,
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='neg', p_pos=0.11214806822153346, p_neg=0.8878519317784656)\n",
      "Sentiment(classification='neg', p_pos=0.28638306190904067, p_neg=0.7136169380909578)\n",
      "Sentiment(classification='pos', p_pos=0.6302232656151758, p_neg=0.3697767343848223)\n",
      "Sentiment(classification='pos', p_pos=0.571914459889252, p_neg=0.42808554011074645)\n",
      "Sentiment(classification='pos', p_pos=0.8823677136614579, p_neg=0.11763228633853988)\n",
      "Sentiment(classification='pos', p_pos=0.9932817425597105, p_neg=0.006718257440289915)\n",
      "Sentiment(classification='pos', p_pos=0.90253775511246, p_neg=0.09746224488754142)\n",
      "Sentiment(classification='pos', p_pos=0.7166666666666666, p_neg=0.28333333333333344)\n",
      "Sentiment(classification='pos', p_pos=0.6218878971389639, p_neg=0.378112102861038)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(TextBlob(st[\"message\"][x], analyzer=NaiveBayesAnalyzer()).sentiment)"
=======
    "raw.head()"
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nothing can get this over . Maybe buyout will do it. Like tops i guess.\n",
      " [Aug Calls] up + . Alerted at on Aug : AM Peak after alert on \n",
      "Peak profit for the last expired option alerts for . | . | . | . | . | . |\n",
      " Last six months, option alerts peaked above percent after they were posted\n",
      " down. Not looking good for Tuesday. Fed will make it worse. Market Watch: Asian markets slip as tensions remain high after attack on Saudi oil facilities\n",
      " always a solid buy for portfolio. Also, now over followers & gaining, you guys are awesome! ??\n",
      " China says 'vice ministerial' officials will be in Washington for trade talks cnbc.com china s...\n",
      " it's awesome\n",
      " everyone please report All he does is spam every company with technical analysis Videos that arent even analyzing anything just a stupid crappy way to get you views for his pathetic YouTube channel\n",
      " ??\n"
     ]
=======
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'neutral', 'irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
    }
   ],
   "source": [
    "raw.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = raw[raw.Sentiment != 'irrelevant']\n",
    "test.drop(['Topic', 'TweetId', 'TweetDate'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 125,
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'TweetText'] = test.loc[:, 'TweetText'].apply(lambda x: html.unescape(x))\n",
    "test.loc[:, 'TweetText'] = test.loc[:, 'TweetText'].apply(lambda x: re.sub(r'(www\\.|https?://).*?(\\s|$)|@.*?(\\s|$)|\\$.*?(\\s|$)|\\d|\\%|\\\\|/|-|_', ' ', x))\n",
    "test.loc[:, 'TweetText'] = test.loc[:, 'TweetText'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 126,
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Now all has to do is get swype on the iphone a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>will be adding more carrier support to the iP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>Hilarious video guy does a duet with 's Siri. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>you made it too easy for me to switch to iPho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                          TweetText\n",
       "0  positive  Now all has to do is get swype on the iphone a...\n",
       "1  positive   will be adding more carrier support to the iP...\n",
       "2  positive  Hilarious video guy does a duet with 's Siri. ...\n",
       "3  positive   you made it too easy for me to switch to iPho...\n",
       "4  positive  I just realized that the reason I got into twi..."
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 22,
=======
   "cell_type": "markdown",
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "metadata": {},
   "source": [
    "## Testing TextBlob"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time()    \n",
    "test.loc[:50, 'TextBlob Sentiment Score'] = test.loc[:50, ['TweetText']].apply(lambda x: TextBlob(x[0], analyzer=NaiveBayesAnalyzer()).sentiment[1], axis=1)\n",
    "time_TextBlob = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477.015625\n"
     ]
    }
   ],
   "source": [
    "print(time_TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>TextBlob Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>now all has to do is get swype on the iphone a...</td>\n",
       "      <td>0.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>will be adding more carrier support to the ip...</td>\n",
       "      <td>0.696821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>hilarious video guy does a duet with 's siri. ...</td>\n",
       "      <td>0.856974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>you made it too easy for me to switch to ipho...</td>\n",
       "      <td>0.637182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>i just realized that the reason i got into twi...</td>\n",
       "      <td>0.398939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                          TweetText  \\\n",
       "0  positive  now all has to do is get swype on the iphone a...   \n",
       "1  positive   will be adding more carrier support to the ip...   \n",
       "2  positive  hilarious video guy does a duet with 's siri. ...   \n",
       "3  positive   you made it too easy for me to switch to ipho...   \n",
       "4  positive  i just realized that the reason i got into twi...   \n",
       "\n",
       "   TextBlob Sentiment Score  \n",
       "0                  0.407200  \n",
       "1                  0.696821  \n",
       "2                  0.856974  \n",
       "3                  0.637182  \n",
       "4                  0.398939  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_TextBlob(x):\n",
    "    if x >= 0.6:\n",
    "        return \"positive\"\n",
    "    elif x <= 0.4:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "test.loc[:, 'TextBlob Sentiment'] = test.loc[:, ['TextBlob Sentiment Score']].apply(lambda x: get_class_TextBlob(x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'TextBlob Match'] = np.where(test.loc[:, 'TextBlob Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Collecting flair\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/e3/389c2dd8d0e6ca1d8fad11aa4940e8df6909a26a5d954c0eff01f0d78b57/flair-0.4.3-py3-none-any.whl (180kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 9.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sklearn (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: pytest>=3.6.4 in /anaconda3/lib/python3.7/site-packages (from flair) (4.0.2)\n",
      "Collecting segtok>=1.5.7 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
      "Collecting deprecated>=1.2.4 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /anaconda3/lib/python3.7/site-packages (from flair) (0.2.0)\n",
      "Collecting regex (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
      "\u001b[K    100% |████████████████████████████████| 655kB 6.9MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting hyperopt>=0.1.1 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/12/704382c3081df3ae3f9d96fe6afb62efa2fa9749be20c301cd2797fb0b52/hyperopt-0.1.2-py3-none-any.whl (115kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 8.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /anaconda3/lib/python3.7/site-packages (from flair) (3.0.2)\n",
      "Collecting mpld3==0.3 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K    100% |████████████████████████████████| 798kB 3.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bpemb>=0.2.9 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /anaconda3/lib/python3.7/site-packages (from flair) (1.24.1)\n",
      "Collecting tabulate (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /anaconda3/lib/python3.7/site-packages (from flair) (4.28.1)\n",
      "Collecting sqlitedict>=1.6.0 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Collecting torch>=1.1.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/88/7640344d841e97b9a1531385caac39d984b2c6f4abd1376e1ce0de3a0933/torch-1.2.0-cp37-none-macosx_10_7_x86_64.whl (59.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 59.9MB 831kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting langdetect (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 3.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gensim>=3.4.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/3a/32a1edf4f335eba0873021a7ddb3230f05dedd2b5450960118b402ca0771/gensim-3.8.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.7MB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython==7.6.1 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n",
      "\u001b[K    100% |████████████████████████████████| 778kB 4.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pytorch-transformers>=1.1.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 7.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /anaconda3/lib/python3.7/site-packages (from sklearn->flair) (0.20.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (40.6.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (18.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (4.3.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.2.1)\n",
      "Requirement already satisfied: pluggy>=0.7 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (0.8.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /anaconda3/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.10.11)\n",
      "Requirement already satisfied: scipy in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.1.0)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.17.1)\n",
      "Collecting pymongo (from hyperopt>=0.1.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/8c/ec46f4aa95515989711a7893e64c30f9d33c58eaccc01f8f37c4513739a2/pymongo-3.9.0-cp37-cp37m-macosx_10_6_intel.whl (378kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 3.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (2.2)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.15.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.7.5)\n",
      "Collecting sentencepiece (from bpemb>=0.2.9->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/7d/f077c7d6c8dc958207960896b35ca1bbf6128527b8a6d4c4aef862660489/sentencepiece-0.1.83-cp37-cp37m-macosx_10_6_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 4.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from bpemb>=0.2.9->flair) (2.21.0)\n",
      "Collecting smart-open>=1.7.0 (from gensim>=3.4.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/c0/25d19badc495428dec6a4bf7782de617ee0246a9211af75b302a2681dea7/smart_open-1.8.4.tar.gz (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 5.8MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jedi>=0.10 in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.13.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.6.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.3.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (2.0.7)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.1.0)\n",
      "Requirement already satisfied: pygments in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (2.3.1)\n",
      "Requirement already satisfied: pickleshare in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.7.5)\n",
      "Requirement already satisfied: backcall in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.1.0)\n",
      "Requirement already satisfied: decorator in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses (from pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/04/b92425ca552116afdb7698fa3f00ca1c975cfd86a847cf132fd813c5d901/sacremoses-0.0.34.tar.gz (859kB)\n",
      "\u001b[K    100% |████████████████████████████████| 860kB 5.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting boto3 (from pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/b0/50b8c1805dc10b32327eb7b90534c3c3b241b2391a625187c7497f88a829/boto3-1.9.233-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 7.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests->bpemb>=0.2.9->flair) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n",
      "Requirement already satisfied: boto>=2.32 in /anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.3.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
      "Requirement already satisfied: click in /anaconda3/lib/python3.7/site-packages (from sacremoses->pytorch-transformers>=1.1.0->flair) (7.0)\n",
      "Collecting joblib (from sacremoses->pytorch-transformers>=1.1.0->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 7.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting botocore<1.13.0,>=1.12.233 (from boto3->pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/14/a3dc6e29ceb7f45bb64bdf144ece5b3657bbfffbf0480a603aae89cd5296/botocore-1.12.233-py2.py3-none-any.whl (5.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.7MB 3.4MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->pytorch-transformers>=1.1.0->flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.233->boto3->pytorch-transformers>=1.1.0->flair) (0.14)\n",
      "Building wheels for collected packages: sklearn, segtok, regex, mpld3, tabulate, sqlitedict, langdetect, smart-open, sacremoses\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Running setup.py bdist_wheel for segtok ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
      "  Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
      "  Running setup.py bdist_wheel for mpld3 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "  Running setup.py bdist_wheel for tabulate ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "  Running setup.py bdist_wheel for sqlitedict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Running setup.py bdist_wheel for langdetect ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/5f/ea/fb/5b1a947b369724063b2617011f1540c44eb00e28c3d2ca8692\n",
      "  Running setup.py bdist_wheel for sacremoses ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/07/b9/5b/8bd674c23e962fbff34420a9fa7a2c374d591ecadd5bc37684\n",
      "Successfully built sklearn segtok regex mpld3 tabulate sqlitedict langdetect smart-open sacremoses\n",
      "Installing collected packages: sklearn, regex, segtok, deprecated, pymongo, hyperopt, mpld3, jmespath, botocore, s3transfer, boto3, smart-open, gensim, sentencepiece, bpemb, tabulate, sqlitedict, torch, langdetect, ipython, joblib, sacremoses, pytorch-transformers, flair\n",
      "  Found existing installation: torch 1.0.0\n",
      "    Uninstalling torch-1.0.0:\n",
      "      Successfully uninstalled torch-1.0.0\n",
      "  Found existing installation: ipython 7.2.0\n",
      "    Uninstalling ipython-7.2.0:\n",
      "      Successfully uninstalled ipython-7.2.0\n",
      "Successfully installed boto3-1.9.233 botocore-1.12.233 bpemb-0.3.0 deprecated-1.2.6 flair-0.4.3 gensim-3.8.0 hyperopt-0.1.2 ipython-7.6.1 jmespath-0.9.4 joblib-0.13.2 langdetect-1.0.7 mpld3-0.3 pymongo-3.9.0 pytorch-transformers-1.2.0 regex-2019.8.19 s3transfer-0.2.1 sacremoses-0.0.34 segtok-1.5.7 sentencepiece-0.1.83 sklearn-0.0 smart-open-1.8.4 sqlitedict-1.6.0 tabulate-0.8.3 torch-1.2.0\n"
=======
      "0.48\n"
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
     ]
    }
   ],
   "source": [
    "TextBlob_accuracy = (test['TextBlob Match'][:50] == 'Yes').sum() / 50\n",
    "print(TextBlob_accuracy)"
   ]
  },
  {
<<<<<<< HEAD
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
=======
   "cell_type": "markdown",
   "metadata": {},
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "source": [
    "## Testing VADER"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./Data/twitter_corpus-master/full-corpus.csv', header=0)"
=======
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time() \n",
    "test.loc[:, 'VADER Sentiment Score'] = test.loc[:, ['TweetText']].apply(lambda x: sia.polarity_scores(x[0])['compound'], axis=1)\n",
    "time_VADAR = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_VADER(x):\n",
    "    if x >= 0.3:\n",
    "        return \"positive\"\n",
    "    elif x <= -0.3:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "test.loc[:, 'VADER Sentiment'] = test.loc[:, ['VADER Sentiment Score']].apply(lambda x: get_class_VADER(x[0]), axis=1)"
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126404574230740992</td>\n",
       "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126395626979196928</td>\n",
       "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126394830791254016</td>\n",
       "      <td>Tue Oct 18 20:30:50 +0000 2011</td>\n",
       "      <td>I'm a current @Blackberry user, little bit dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126379685453119488</td>\n",
       "      <td>Tue Oct 18 19:30:39 +0000 2011</td>\n",
       "      <td>The 16 strangest things Siri has said so far. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126377656416612353</td>\n",
       "      <td>Tue Oct 18 19:22:35 +0000 2011</td>\n",
       "      <td>Great up close &amp; personal event @Apple tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126373779483004928</td>\n",
       "      <td>Tue Oct 18 19:07:11 +0000 2011</td>\n",
       "      <td>From which companies do you experience the bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126366353757179904</td>\n",
       "      <td>Tue Oct 18 18:37:41 +0000 2011</td>\n",
       "      <td>Just apply for a job at @Apple, hope they call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment             TweetId                       TweetDate  \\\n",
       "0  apple  positive  126415614616154112  Tue Oct 18 21:53:25 +0000 2011   \n",
       "1  apple  positive  126404574230740992  Tue Oct 18 21:09:33 +0000 2011   \n",
       "2  apple  positive  126402758403305474  Tue Oct 18 21:02:20 +0000 2011   \n",
       "3  apple  positive  126397179614068736  Tue Oct 18 20:40:10 +0000 2011   \n",
       "4  apple  positive  126395626979196928  Tue Oct 18 20:34:00 +0000 2011   \n",
       "5  apple  positive  126394830791254016  Tue Oct 18 20:30:50 +0000 2011   \n",
       "6  apple  positive  126379685453119488  Tue Oct 18 19:30:39 +0000 2011   \n",
       "7  apple  positive  126377656416612353  Tue Oct 18 19:22:35 +0000 2011   \n",
       "8  apple  positive  126373779483004928  Tue Oct 18 19:07:11 +0000 2011   \n",
       "9  apple  positive  126366353757179904  Tue Oct 18 18:37:41 +0000 2011   \n",
       "\n",
       "                                           TweetText  \n",
       "0  Now all @Apple has to do is get swype on the i...  \n",
       "1  @Apple will be adding more carrier support to ...  \n",
       "2  Hilarious @youtube video - guy does a duet wit...  \n",
       "3  @RIM you made it too easy for me to switch to ...  \n",
       "4  I just realized that the reason I got into twi...  \n",
       "5  I'm a current @Blackberry user, little bit dis...  \n",
       "6  The 16 strangest things Siri has said so far. ...  \n",
       "7  Great up close & personal event @Apple tonight...  \n",
       "8  From which companies do you experience the bes...  \n",
       "9  Just apply for a job at @Apple, hope they call...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "source": [
    "test.loc[:, 'VADER Match'] = np.where(test.loc[:, 'VADER Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
=======
   "execution_count": 105,
   "metadata": {},
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6039719626168224\n"
     ]
    }
   ],
   "source": [
    "VADER_accuracy = (test['VADER Match'] == 'Yes').sum() / len(test)\n",
    "print(VADER_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model trained by Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 18:56:10,829 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/classy-imdb-en-rnn-cuda%3A0/imdb-v0.4.pt not found in cache, downloading to /var/folders/76/x5w4_hbd06zd9g8rj1tv2bf80000gn/T/tmprnt0vks7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 127042560/1501979561 [04:59<49:21:24, 7738.09B/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e258f15712cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflair_sentement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-sentiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#include the sentence here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m475\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m485\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/nn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36m_fetch_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# File, and it exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flair_sentement = flair.models.TextClassifier.load('en-sentiment')\n",
    "\n",
    "#include the sentence here\n",
    "for x in range(475,485):\n",
    "    s = flair.data.Sentence()\n",
    "\n",
    "    flair_sentement.predict(s)\n",
    "    total_sentiment = s.labels\n",
    "    total_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125224588253741056</td>\n",
       "      <td>Sat Oct 15 15:00:43 +0000 2011</td>\n",
       "      <td>#Siri went down for a little while last night....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125223685194915840</td>\n",
       "      <td>Sat Oct 15 14:57:07 +0000 2011</td>\n",
       "      <td>@ford should have teamed up with @Apple instea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125204228967903232</td>\n",
       "      <td>Sat Oct 15 13:39:49 +0000 2011</td>\n",
       "      <td>Installed io5 - fine on ipad but wiped wife's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125202037293064192</td>\n",
       "      <td>Sat Oct 15 13:31:06 +0000 2011</td>\n",
       "      <td>RT @gdcurry: Really @Apple?  What have you don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125129328446017536</td>\n",
       "      <td>Sat Oct 15 08:42:11 +0000 2011</td>\n",
       "      <td>DAMN YOU !!! @apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126417484017451009</td>\n",
       "      <td>Tue Oct 18 22:00:51 +0000 2011</td>\n",
       "      <td>@Late_Show I would have watched but the folks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126415742177513472</td>\n",
       "      <td>Tue Oct 18 21:53:56 +0000 2011</td>\n",
       "      <td>RT @rdingwell: .@Apple has a record quarter an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126415618625912832</td>\n",
       "      <td>Tue Oct 18 21:53:26 +0000 2011</td>\n",
       "      <td>Hey @apple, androids releasing brand new state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126414657836687362</td>\n",
       "      <td>Tue Oct 18 21:49:37 +0000 2011</td>\n",
       "      <td>.@Apple has a record quarter and because a bun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126410146703351808</td>\n",
       "      <td>Tue Oct 18 21:31:42 +0000 2011</td>\n",
       "      <td>@Apple how fun wouldn't it be if it was possib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic Sentiment             TweetId                       TweetDate  \\\n",
       "475  apple  negative  125224588253741056  Sat Oct 15 15:00:43 +0000 2011   \n",
       "476  apple  negative  125223685194915840  Sat Oct 15 14:57:07 +0000 2011   \n",
       "477  apple  negative  125204228967903232  Sat Oct 15 13:39:49 +0000 2011   \n",
       "478  apple  negative  125202037293064192  Sat Oct 15 13:31:06 +0000 2011   \n",
       "479  apple  negative  125129328446017536  Sat Oct 15 08:42:11 +0000 2011   \n",
       "480  apple   neutral  126417484017451009  Tue Oct 18 22:00:51 +0000 2011   \n",
       "481  apple   neutral  126415742177513472  Tue Oct 18 21:53:56 +0000 2011   \n",
       "482  apple   neutral  126415618625912832  Tue Oct 18 21:53:26 +0000 2011   \n",
       "483  apple   neutral  126414657836687362  Tue Oct 18 21:49:37 +0000 2011   \n",
       "484  apple   neutral  126410146703351808  Tue Oct 18 21:31:42 +0000 2011   \n",
       "\n",
       "                                             TweetText  \n",
       "475  #Siri went down for a little while last night....  \n",
       "476  @ford should have teamed up with @Apple instea...  \n",
       "477  Installed io5 - fine on ipad but wiped wife's ...  \n",
       "478  RT @gdcurry: Really @Apple?  What have you don...  \n",
       "479                                DAMN YOU !!! @apple  \n",
       "480  @Late_Show I would have watched but the folks ...  \n",
       "481  RT @rdingwell: .@Apple has a record quarter an...  \n",
       "482  Hey @apple, androids releasing brand new state...  \n",
       "483  .@Apple has a record quarter and because a bun...  \n",
       "484  @Apple how fun wouldn't it be if it was possib...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(word_list):\n",
    "    return dict([(word, True) for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "   # Load positive and negative reviews  \n",
    "    positive_fileids = movie_reviews.fileids('pos')\n",
    "    negative_fileids = movie_reviews.fileids('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_positive = [(extract_features(movie_reviews.words(fileids=[f])), 'Positive') for f in positive_fileids]\n",
    "features_negative = [(extract_features(movie_reviews.words(fileids=[f])), 'Negative') for f in negative_fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test (80/20)\n",
    "threshold_factor = 0.8\n",
    "threshold_positive = int(threshold_factor * len(features_positive))\n",
    "threshold_negative = int(threshold_factor * len(features_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_positive[:threshold_positive] + features_negative[:threshold_negative]\n",
    "features_test = features_positive[threshold_positive:] + features_negative[threshold_negative:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(features_train)\n",
    "print(\"\\nAccuracy of the classifier:\", nltk.classify.util.accuracy(classifier, features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
   "source": [
    "start = time.process_time() \n",
    "temp = []\n",
    "for x in test[\"TweetText\"]:\n",
    "    probdist = classifier.prob_classify(extract_features(x.split()))\n",
    "    pred_sentiment = probdist.max()\n",
    "    probability = probdist.prob(pred_sentiment)\n",
    "    temp.append([pred_sentiment, probability])\n",
    "time_NB = time.process_time() - start\n",
    "    \n",
    "sentiments = []\n",
    "for x in temp:\n",
    "    if ((x[0] == 'Positive') and (x[1] >= 0.7)):\n",
    "        sentiment = 'positive'\n",
    "    elif ((x[0] == 'Negative') and (x[1] >= 0.7)):\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "    sentiments.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df = pd.DataFrame({'NB Sentiment':sentiments})\n",
    "test['NB Sentiment'] = sentiments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'NB Match'] = np.where(test.loc[:, 'NB Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_accuracy = (test['NB Match'] == 'Yes').sum() / len(test)\n",
    "print(NB_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.wsd import lesk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def get_sentiword_score(message):\n",
    "        \"\"\"\n",
    "            takes a message and performs following operations:\n",
    "            1) tokenize\n",
    "            2) POS tagging\n",
    "            3) reduce text to nouns, verbs, adjectives, adverbs\n",
    "            4) lemmatize the words\n",
    "            for each selected tag, if more than one sense exists, performs word sense disambiguation\n",
    "            using lesk algorithm and finally returns positivity score, negativity score from\n",
    "            sentiwordnet lexicon\n",
    "        \"\"\"\n",
    "\n",
    "        tokens = word_tokenize(message)\n",
    "        pos = pos_tag(tokens)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        selected_tags = list()\n",
    "        scores = list()\n",
    "\n",
    "        for i in range(len(pos)):\n",
    "            if pos[i][1].startswith('J'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'a'), 'a'))\n",
    "            elif pos[i][1].startswith('V'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'v'), 'v'))\n",
    "            elif pos[i][1].startswith('N'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'n'), 'n'))\n",
    "            elif pos[i][1].startswith('R'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'r'), 'r'))\n",
    "\n",
    "        # score list: [(sense name, pos score, neg score)]\n",
    "        for i in range(len(selected_tags)):\n",
    "            senses = list(swn.senti_synsets(selected_tags[i][0], selected_tags[i][1]))\n",
    "            if len(senses) == 1:\n",
    "                scores.append((senses[0].synset.name(), senses[0].pos_score(), senses[0].neg_score()))\n",
    "            elif len(senses) > 1:\n",
    "                sense = lesk(tokens, selected_tags[i][0], selected_tags[i][1])\n",
    "                if sense is None:\n",
    "                    # take average score of all original senses\n",
    "                    pos_score = 0\n",
    "                    neg_score = 0\n",
    "                    for i in senses:\n",
    "                        pos_score += i.pos_score()\n",
    "                        neg_score += i.neg_score()\n",
    "                    scores.append((senses[0].synset.name(), pos_score/len(senses), neg_score/len(senses)))\n",
    "                else:\n",
    "                    sense = swn.senti_synset(sense.name())\n",
    "                    scores.append((sense.synset.name(), sense.pos_score(), sense.neg_score()))\n",
    "\n",
    "        \"\"\"\n",
    "            there are a number of ways for aggregating sentiment scores\n",
    "            1) sum up all scores\n",
    "            2) average all scores (or only for non zero scores)\n",
    "            3) (1) or (2) but only for adjectives\n",
    "            4) if pos score greater than neg score +1 vote else -1 vote\n",
    "            here we are summing up the positive and negative scores to be used by classifier.\n",
    "            whenever we encounter a negative word, we reverse the positive and negative score.\n",
    "        \"\"\"\n",
    "\n",
    "        # collected from word stat financial dictionary\n",
    "        negation_words = list(open('Lexicon/lexicon_negation_words.txt').read().split())\n",
    "\n",
    "        # final_score = 0\n",
    "        # counter = 1\n",
    "        # for score in scores:\n",
    "        #     if any(score[0].startswith(x) for x in negation_words):\n",
    "        #         counter *= -1\n",
    "        #     else:\n",
    "        #         if score[1] > score[2]:\n",
    "        #             final_score += counter*score[1]\n",
    "        #         elif score[1] < score[2]:\n",
    "        #             final_score -= counter*score[2]\n",
    "\n",
    "        counter = 1\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for score in scores:\n",
    "            if any(score[0].startswith(x) for x in negation_words):\n",
    "                counter *= -1\n",
    "            else:\n",
    "                if counter == 1:\n",
    "                    pos_score += score[1]\n",
    "                    neg_score += score[2]\n",
    "                elif counter == -1:\n",
    "                    pos_score += score[2]\n",
    "                    neg_score += score[1]\n",
    "\n",
    "        final_score = [pos_score, neg_score]\n",
    "        return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time() \n",
    "scores = []\n",
    "for x in test['TweetText']:\n",
    "    scores.append(get_sentiword_score(x))\n",
    "time_SWN = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = []\n",
    "for x in scores:\n",
    "    if ((x[0] + x[1]) == 0):\n",
    "        ss.append('neutral')\n",
    "    elif (x[0] / (x[0] + x[1]) >= 0.7):\n",
    "        ss.append('positive')\n",
    "    elif (x[1] / (x[0] + x[1]) >= 0.7):\n",
    "        ss.append('negative')\n",
    "    else:\n",
    "        ss.append('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df = pd.DataFrame({'SWN Sentiment':ss})\n",
    "test['SWN Sentiment'] = ss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'SWN Match'] = np.where(test.loc[:, 'SWN Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SWN_accuracy = (test['SWN Match'] == 'Yes').sum() / len(test)\n",
    "print(SWN_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_text_TextBlob = time_TextBlob / 50\n",
    "time_per_text_VADAR = time_VADAR / len(test)\n",
    "time_per_text_NB = time_NB / len(test)\n",
    "time_per_text_SWN = time_SWN / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time taken per tweet (TextBlob):  9.5403125\n",
      "Average time taken per tweet (VADER):  0.0005019713785046728\n",
      "Average time taken per tweet (NB):  0.00010952102803738318\n",
      "Average time taken per tweet (SWN):  0.0055536287967289715\n"
     ]
    }
   ],
   "source": [
    "print(\"Average time taken per tweet (TextBlob): \", time_per_text_TextBlob)\n",
    "print(\"Average time taken per tweet (VADER): \", time_per_text_VADAR)\n",
    "print(\"Average time taken per tweet (NB): \", time_per_text_NB)\n",
    "print(\"Average time taken per tweet (SWN): \", time_per_text_SWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob accuracy:  0.48\n",
      "VADER accuracy:  0.6039719626168224\n",
      "NB accuracy:  0.41296728971962615\n",
      "SWN accuracy:  0.3633177570093458\n"
     ]
    }
   ],
   "source": [
    "print(\"TextBlob accuracy: \", TextBlob_accuracy)\n",
    "print(\"VADER accuracy: \", VADER_accuracy)\n",
    "print(\"NB accuracy: \", NB_accuracy)\n",
    "print(\"SWN accuracy: \", SWN_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test VADAR with stock market lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would have a lower accuracy as it uses a specific lexicon that is not specific to the test set\n",
    "\n",
    "Hence, do not need to include this in the comparison (but can compare VADAR without the lexicon using correlation with the market price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock market lexicon\n",
    "stock_lex = pd.read_csv('./Lexicon/stock_lex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_lex['sentiment'] = (stock_lex['Aff_Score'] + stock_lex['Neg_Score'])/2\n",
    "stock_lex = dict(zip(stock_lex.Item, stock_lex.sentiment))\n",
    "stock_lex = {k:v for k,v in stock_lex.items() if len(k.split(' '))==1}\n",
    "stock_lex_scaled = {}\n",
    "for k, v in stock_lex.items():\n",
    "    if v > 0:\n",
    "        stock_lex_scaled[k] = v / max(stock_lex.values()) * 4\n",
    "    else:\n",
    "        stock_lex_scaled[k] = v / min(stock_lex.values()) * -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loughran and McDonald\n",
    "positive = []\n",
    "with open('./Lexicon/lm_positive.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        positive.append(row[0].strip())\n",
    "    \n",
    "negative = []\n",
    "with open('./Lexicon/lm_negative.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        entry = row[0].strip().split(\" \")\n",
    "        if len(entry) > 1:\n",
    "            negative.extend(entry)\n",
    "        else:\n",
    "            negative.append(entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lex = {}\n",
    "# final_lex.update({word:2.0 for word in positive})\n",
    "# final_lex.update({word:-2.0 for word in negative})\n",
    "final_lex.update(stock_lex_scaled)\n",
    "final_lex.update(sia.lexicon)\n",
    "sia.lexicon = final_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'VADER_lex Sentiment Score'] = test.loc[:, ['TweetText']].apply(lambda x: sia.polarity_scores(x[0])['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_VADER_lex(x):\n",
    "    if x >= 0.3:\n",
    "        return \"positive\"\n",
    "    elif x <= -0.3:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "test.loc[:, 'VADER_lex Sentiment'] = test.loc[:, ['VADER_lex Sentiment Score']].apply(lambda x: get_class_VADER_lex(x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'VADER_lex Match'] = np.where(test.loc[:, 'VADER_lex Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47079439252336447\n"
     ]
    }
   ],
   "source": [
    "VADER_lex_accuracy = (test['VADER_lex Match'] == 'Yes').sum() / len(test)\n",
    "print(VADER_lex_accuracy)"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycorenlp\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/40/e74eb4fc7906d630b73a84c9ae9d824f694bd4c5a1d727b8e18beadff613/pycorenlp-0.3.0.tar.gz\n",
      "Requirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from pycorenlp) (2.21.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (2018.11.29)\n",
      "Building wheels for collected packages: pycorenlp\n",
      "  Running setup.py bdist_wheel for pycorenlp ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/fb/e9/2f/767a7b5f2e82d587a36143c04a21839b4b14bebfb89410d2d5\n",
      "Successfully built pycorenlp\n",
      "Installing collected packages: pycorenlp\n",
      "Successfully installed pycorenlp-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pycorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('Data/twitter_corpus-master/full-corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126404574230740992</td>\n",
       "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126395626979196928</td>\n",
       "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment             TweetId                       TweetDate  \\\n",
       "0  apple  positive  126415614616154112  Tue Oct 18 21:53:25 +0000 2011   \n",
       "1  apple  positive  126404574230740992  Tue Oct 18 21:09:33 +0000 2011   \n",
       "2  apple  positive  126402758403305474  Tue Oct 18 21:02:20 +0000 2011   \n",
       "3  apple  positive  126397179614068736  Tue Oct 18 20:40:10 +0000 2011   \n",
       "4  apple  positive  126395626979196928  Tue Oct 18 20:34:00 +0000 2011   \n",
       "\n",
       "                                           TweetText  \n",
       "0  Now all @Apple has to do is get swype on the i...  \n",
       "1  @Apple will be adding more carrier support to ...  \n",
       "2  Hilarious @youtube video - guy does a duet wit...  \n",
       "3  @RIM you made it too easy for me to switch to ...  \n",
       "4  I just realized that the reason I got into twi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-607cb79a944d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlength_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentimentValue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlength_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlength_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "scores = []\n",
    "for x in data['TweetText']:\n",
    "    res = nlp.annotate(x,\n",
    "                       properties={\n",
    "                           'annotators': 'sentiment',\n",
    "                           'outputFormat': 'json',\n",
    "                           'timeout': 1000,\n",
    "                       })\n",
    "    ss = 0\n",
    "    length_s = 0\n",
    "    for s in res[\"sentences\"]:\n",
    "            ss = ss + int(s[\"sentimentValue\"])\n",
    "            length_s = length_s+1\n",
    "    if (length_s > 0):\n",
    "        score = ss/length_s\n",
    "    if (score < 2):\n",
    "        score_text = 'negative'\n",
    "    elif(score == 2):\n",
    "        score_text = 'neutral'\n",
    "    else: \n",
    "        score_text = 'positive'\n",
    "    \n",
    "    scores.append(score_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic                                                    apple\n",
       "Sentiment                                             negative\n",
       "TweetId                                     125271422431014914\n",
       "TweetDate                       Sat Oct 15 18:06:49 +0000 2011\n",
       "TweetText    remember when people used to say \"flat the fuc...\n",
       "Name: 460, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[460,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3557483731019523\n"
     ]
    }
   ],
   "source": [
    "sentiments = data['Sentiment'][0:460]\n",
    "index = 0\n",
    "correct_counter = 0\n",
    "for x in sentiments:\n",
    "    if x == scores[index]:\n",
    "        correct_counter = correct_counter + 1\n",
    "    \n",
    "print(correct_counter/461)"
   ]
=======
>>>>>>> 599b5b90ac8aa5630b87c786e12cf9dabe8fdd0b
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
