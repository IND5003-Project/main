{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Raphael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\Raphael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "import html\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import csv\n",
    "import time\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with pre-labelled existing data from Twitter\n",
    "raw = pd.read_csv('./Data/twitter_corpus-master/full-corpus.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126404574230740992</td>\n",
       "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126395626979196928</td>\n",
       "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment             TweetId                       TweetDate  \\\n",
       "0  apple  positive  126415614616154112  Tue Oct 18 21:53:25 +0000 2011   \n",
       "1  apple  positive  126404574230740992  Tue Oct 18 21:09:33 +0000 2011   \n",
       "2  apple  positive  126402758403305474  Tue Oct 18 21:02:20 +0000 2011   \n",
       "3  apple  positive  126397179614068736  Tue Oct 18 20:40:10 +0000 2011   \n",
       "4  apple  positive  126395626979196928  Tue Oct 18 20:34:00 +0000 2011   \n",
       "\n",
       "                                           TweetText  \n",
       "0  Now all @Apple has to do is get swype on the i...  \n",
       "1  @Apple will be adding more carrier support to ...  \n",
       "2  Hilarious @youtube video - guy does a duet wit...  \n",
       "3  @RIM you made it too easy for me to switch to ...  \n",
       "4  I just realized that the reason I got into twi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'negative', 'neutral', 'irrelevant'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raphael\\desktop\\y5s1\\ind5003\\lib\\site-packages\\pandas\\core\\frame.py:4097: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "test = raw[raw.Sentiment != 'irrelevant']\n",
    "test.drop(['Topic', 'TweetId', 'TweetDate'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raphael\\desktop\\y5s1\\ind5003\\lib\\site-packages\\pandas\\core\\indexing.py:562: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item_labels[indexer[info_axis]]] = value\n"
     ]
    }
   ],
   "source": [
    "test.loc[:, 'TweetText'] = test.loc[:, 'TweetText'].apply(lambda x: html.unescape(x))\n",
    "test.loc[:, 'TweetText'] = test.loc[:, 'TweetText'].apply(lambda x: re.sub(r'(www\\.|https?://).*?(\\s|$)|@.*?(\\s|$)|\\$.*?(\\s|$)|\\d|\\%|\\\\|/|-|_', ' ', x))\n",
    "test.loc[:, 'TweetText'] = test.loc[:, 'TweetText'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Now all has to do is get swype on the iphone a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>will be adding more carrier support to the iP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>Hilarious video guy does a duet with 's Siri. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>you made it too easy for me to switch to iPho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                          TweetText\n",
       "0  positive  Now all has to do is get swype on the iphone a...\n",
       "1  positive   will be adding more carrier support to the iP...\n",
       "2  positive  Hilarious video guy does a duet with 's Siri. ...\n",
       "3  positive   you made it too easy for me to switch to iPho...\n",
       "4  positive  I just realized that the reason I got into twi..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raphael\\desktop\\y5s1\\ind5003\\lib\\site-packages\\pandas\\core\\indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "c:\\users\\raphael\\desktop\\y5s1\\ind5003\\lib\\site-packages\\pandas\\core\\indexing.py:480: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "test.loc[:50, 'TextBlob Sentiment Score'] = test.loc[:50, ['TweetText']].apply(lambda x: TextBlob(x[0], analyzer=NaiveBayesAnalyzer()).sentiment[1], axis=1)\n",
    "time_TextBlob = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532.0\n"
     ]
    }
   ],
   "source": [
    "print(time_TextBlob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>TextBlob Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>Now all has to do is get swype on the iphone a...</td>\n",
       "      <td>0.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>will be adding more carrier support to the iP...</td>\n",
       "      <td>0.696821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive</td>\n",
       "      <td>Hilarious video guy does a duet with 's Siri. ...</td>\n",
       "      <td>0.856974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>you made it too easy for me to switch to iPho...</td>\n",
       "      <td>0.637182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "      <td>0.398939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                          TweetText  \\\n",
       "0  positive  Now all has to do is get swype on the iphone a...   \n",
       "1  positive   will be adding more carrier support to the iP...   \n",
       "2  positive  Hilarious video guy does a duet with 's Siri. ...   \n",
       "3  positive   you made it too easy for me to switch to iPho...   \n",
       "4  positive  I just realized that the reason I got into twi...   \n",
       "\n",
       "   TextBlob Sentiment Score  \n",
       "0                  0.407200  \n",
       "1                  0.696821  \n",
       "2                  0.856974  \n",
       "3                  0.637182  \n",
       "4                  0.398939  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_TextBlob(x):\n",
    "    if x >= 0.6:\n",
    "        return \"positive\"\n",
    "    elif x <= 0.4:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "test.loc[:, 'TextBlob Sentiment'] = test.loc[:, ['TextBlob Sentiment Score']].apply(lambda x: get_class_TextBlob(x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'TextBlob Match'] = np.where(test.loc[:, 'TextBlob Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48\n"
     ]
    }
   ],
   "source": [
    "TextBlob_accuracy = (test['TextBlob Match'][:50] == 'Yes').sum() / 50\n",
    "print(TextBlob_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time() \n",
    "test.loc[:, 'VADER Sentiment Score'] = test.loc[:, ['TweetText']].apply(lambda x: sia.polarity_scores(x[0])['compound'], axis=1)\n",
    "time_VADAR = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_VADER(x):\n",
    "    if x >= 0.3:\n",
    "        return \"positive\"\n",
    "    elif x <= -0.3:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "test.loc[:, 'VADER Sentiment'] = test.loc[:, ['VADER Sentiment Score']].apply(lambda x: get_class_VADER(x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'VADER Match'] = np.where(test.loc[:, 'VADER Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6016355140186916\n"
     ]
    }
   ],
   "source": [
    "VADER_accuracy = (test['VADER Match'] == 'Yes').sum() / len(test)\n",
    "print(VADER_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model trained by Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(word_list):\n",
    "    return dict([(word, True) for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "   # Load positive and negative reviews  \n",
    "    positive_fileids = movie_reviews.fileids('pos')\n",
    "    negative_fileids = movie_reviews.fileids('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_positive = [(extract_features(movie_reviews.words(fileids=[f])), 'Positive') for f in positive_fileids]\n",
    "features_negative = [(extract_features(movie_reviews.words(fileids=[f])), 'Negative') for f in negative_fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test (80/20)\n",
    "threshold_factor = 0.8\n",
    "threshold_positive = int(threshold_factor * len(features_positive))\n",
    "threshold_negative = int(threshold_factor * len(features_negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_positive[:threshold_positive] + features_negative[:threshold_negative]\n",
    "features_test = features_positive[threshold_positive:] + features_negative[threshold_negative:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of the classifier: 0.735\n"
     ]
    }
   ],
   "source": [
    "# Train a Naive Bayes classifier\n",
    "classifier = NaiveBayesClassifier.train(features_train)\n",
    "print(\"\\nAccuracy of the classifier:\", nltk.classify.util.accuracy(classifier, features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time() \n",
    "temp = []\n",
    "for x in test[\"TweetText\"]:\n",
    "    probdist = classifier.prob_classify(extract_features(x.split()))\n",
    "    pred_sentiment = probdist.max()\n",
    "    probability = probdist.prob(pred_sentiment)\n",
    "    temp.append([pred_sentiment, probability])\n",
    "time_NB = time.process_time() - start\n",
    "    \n",
    "sentiments = []\n",
    "for x in temp:\n",
    "    if (x[0] == 'Positive') and (x[1] > 0.7):\n",
    "        sentiment = 'positive'\n",
    "    elif (x[0] == 'Negative') and (x[1] > 0.7):\n",
    "        sentiment = 'negative'\n",
    "    else:\n",
    "        sentiment = 'neutral'\n",
    "\n",
    "    sentiments.append(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raphael\\desktop\\y5s1\\ind5003\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "sentiments_df = pd.DataFrame({'NB Sentiment':sentiments})\n",
    "test['NB Sentiment'] = sentiments_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'NB Match'] = np.where(test.loc[:, 'NB Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41296728971962615\n"
     ]
    }
   ],
   "source": [
    "NB_accuracy = (test['NB Match'] == 'Yes').sum() / len(test)\n",
    "print(NB_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing using SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.wsd import lesk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def get_sentiword_score(message):\n",
    "        \"\"\"\n",
    "            takes a message and performs following operations:\n",
    "            1) tokenize\n",
    "            2) POS tagging\n",
    "            3) reduce text to nouns, verbs, adjectives, adverbs\n",
    "            4) lemmatize the words\n",
    "            for each selected tag, if more than one sense exists, performs word sense disambiguation\n",
    "            using lesk algorithm and finally returns positivity score, negativity score from\n",
    "            sentiwordnet lexicon\n",
    "        \"\"\"\n",
    "\n",
    "        tokens = word_tokenize(message)\n",
    "        pos = pos_tag(tokens)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        selected_tags = list()\n",
    "        scores = list()\n",
    "\n",
    "        for i in range(len(pos)):\n",
    "            if pos[i][1].startswith('J'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'a'), 'a'))\n",
    "            elif pos[i][1].startswith('V'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'v'), 'v'))\n",
    "            elif pos[i][1].startswith('N'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'n'), 'n'))\n",
    "            elif pos[i][1].startswith('R'):\n",
    "                selected_tags.append((lemmatizer.lemmatize(pos[i][0], 'r'), 'r'))\n",
    "\n",
    "        # score list: [(sense name, pos score, neg score)]\n",
    "        for i in range(len(selected_tags)):\n",
    "            senses = list(swn.senti_synsets(selected_tags[i][0], selected_tags[i][1]))\n",
    "            if len(senses) == 1:\n",
    "                scores.append((senses[0].synset.name(), senses[0].pos_score(), senses[0].neg_score()))\n",
    "            elif len(senses) > 1:\n",
    "                sense = lesk(tokens, selected_tags[i][0], selected_tags[i][1])\n",
    "                if sense is None:\n",
    "                    # take average score of all original senses\n",
    "                    pos_score = 0\n",
    "                    neg_score = 0\n",
    "                    for i in senses:\n",
    "                        pos_score += i.pos_score()\n",
    "                        neg_score += i.neg_score()\n",
    "                    scores.append((senses[0].synset.name(), pos_score/len(senses), neg_score/len(senses)))\n",
    "                else:\n",
    "                    sense = swn.senti_synset(sense.name())\n",
    "                    scores.append((sense.synset.name(), sense.pos_score(), sense.neg_score()))\n",
    "\n",
    "        \"\"\"\n",
    "            there are a number of ways for aggregating sentiment scores\n",
    "            1) sum up all scores\n",
    "            2) average all scores (or only for non zero scores)\n",
    "            3) (1) or (2) but only for adjectives\n",
    "            4) if pos score greater than neg score +1 vote else -1 vote\n",
    "            here we are summing up the positive and negative scores to be used by classifier.\n",
    "            whenever we encounter a negative word, we reverse the positive and negative score.\n",
    "        \"\"\"\n",
    "\n",
    "        # collected from word stat financial dictionary\n",
    "        negation_words = list(open('Lexicon/lexicon_negation_words.txt').read().split())\n",
    "\n",
    "        # final_score = 0\n",
    "        # counter = 1\n",
    "        # for score in scores:\n",
    "        #     if any(score[0].startswith(x) for x in negation_words):\n",
    "        #         counter *= -1\n",
    "        #     else:\n",
    "        #         if score[1] > score[2]:\n",
    "        #             final_score += counter*score[1]\n",
    "        #         elif score[1] < score[2]:\n",
    "        #             final_score -= counter*score[2]\n",
    "\n",
    "        counter = 1\n",
    "        pos_score = 0\n",
    "        neg_score = 0\n",
    "        for score in scores:\n",
    "            if any(score[0].startswith(x) for x in negation_words):\n",
    "                counter *= -1\n",
    "            else:\n",
    "                if counter == 1:\n",
    "                    pos_score += score[1]\n",
    "                    neg_score += score[2]\n",
    "                elif counter == -1:\n",
    "                    pos_score += score[2]\n",
    "                    neg_score += score[1]\n",
    "\n",
    "        final_score = [pos_score, neg_score]\n",
    "        return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.process_time() \n",
    "scores = []\n",
    "for x in test['TweetText']:\n",
    "    scores.append(get_sentiword_score(x))\n",
    "time_SWN = time.process_time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = []\n",
    "for x in scores:\n",
    "    if x[0] + x[1] == 0:\n",
    "        ss.append('neutral')\n",
    "    elif (x[0] / (x[0] + x[1])) > 0.6:\n",
    "        ss.append('positive')\n",
    "    elif (x[1] / (x[0] + x[1])) > 0.6:\n",
    "        ss.append('negative')\n",
    "    else: \n",
    "        ss.append('neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\raphael\\desktop\\y5s1\\ind5003\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ss_df = pd.DataFrame({'SWN Sentiment':ss})\n",
    "test['SWN Sentiment'] = ss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'SWN Match'] = np.where(test.loc[:, 'SWN Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3279789719626168\n"
     ]
    }
   ],
   "source": [
    "SWN_accuracy = (test['SWN Match'] == 'Yes').sum() / len(test)\n",
    "print(SWN_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_per_text_TextBlob = time_TextBlob / 50\n",
    "time_per_text_VADAR = time_VADAR / len(test)\n",
    "time_per_text_NB = time_NB / len(test)\n",
    "time_per_text_SWN = time_SWN / len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time taken per tweet (TextBlob):  10.64\n",
      "Average time taken per tweet (VADER):  0.0005476051401869158\n",
      "Average time taken per tweet (NB):  0.00010039427570093458\n",
      "Average time taken per tweet (SWN):  0.009167822721962617\n"
     ]
    }
   ],
   "source": [
    "print(\"Average time taken per tweet (TextBlob): \", time_per_text_TextBlob)\n",
    "print(\"Average time taken per tweet (VADER): \", time_per_text_VADAR)\n",
    "print(\"Average time taken per tweet (NB): \", time_per_text_NB)\n",
    "print(\"Average time taken per tweet (SWN): \", time_per_text_SWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob accuracy:  0.48\n",
      "VADER accuracy:  0.6016355140186916\n",
      "NB accuracy:  0.41296728971962615\n",
      "SWN accuracy:  0.3279789719626168\n"
     ]
    }
   ],
   "source": [
    "print(\"TextBlob accuracy: \", TextBlob_accuracy)\n",
    "print(\"VADER accuracy: \", VADER_accuracy)\n",
    "print(\"NB accuracy: \", NB_accuracy)\n",
    "print(\"SWN accuracy: \", SWN_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test VADAR with stock market lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would have a lower accuracy as it uses a specific lexicon that is not specific to the test set\n",
    "\n",
    "Hence, do not need to include this in the comparison (but can compare VADAR without the lexicon using correlation with the market price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock market lexicon\n",
    "stock_lex = pd.read_csv('./Lexicon/stock_lex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_lex['sentiment'] = (stock_lex['Aff_Score'] + stock_lex['Neg_Score'])/2\n",
    "stock_lex = dict(zip(stock_lex.Item, stock_lex.sentiment))\n",
    "stock_lex = {k:v for k,v in stock_lex.items() if len(k.split(' '))==1}\n",
    "stock_lex_scaled = {}\n",
    "for k, v in stock_lex.items():\n",
    "    if v > 0:\n",
    "        stock_lex_scaled[k] = v / max(stock_lex.values()) * 4\n",
    "    else:\n",
    "        stock_lex_scaled[k] = v / min(stock_lex.values()) * -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loughran and McDonald\n",
    "positive = []\n",
    "with open('./Lexicon/lm_positive.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        positive.append(row[0].strip())\n",
    "    \n",
    "negative = []\n",
    "with open('./Lexicon/lm_negative.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        entry = row[0].strip().split(\" \")\n",
    "        if len(entry) > 1:\n",
    "            negative.extend(entry)\n",
    "        else:\n",
    "            negative.append(entry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lex = {}\n",
    "# final_lex.update({word:2.0 for word in positive})\n",
    "# final_lex.update({word:-2.0 for word in negative})\n",
    "final_lex.update(stock_lex_scaled)\n",
    "final_lex.update(sia.lexicon)\n",
    "sia.lexicon = final_lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'VADER_lex Sentiment Score'] = test.loc[:, ['TweetText']].apply(lambda x: sia.polarity_scores(x[0])['compound'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_VADER_lex(x):\n",
    "    if x >= 0.3:\n",
    "        return \"positive\"\n",
    "    elif x <= -0.3:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "test.loc[:, 'VADER_lex Sentiment'] = test.loc[:, ['VADER_lex Sentiment Score']].apply(lambda x: get_class_VADER_lex(x[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[:, 'VADER_lex Match'] = np.where(test.loc[:, 'VADER_lex Sentiment'] == test.loc[:, 'Sentiment'], 'Yes', 'No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47079439252336447\n"
     ]
    }
   ],
   "source": [
    "VADER_lex_accuracy = (test['VADER_lex Match'] == 'Yes').sum() / len(test)\n",
    "print(VADER_lex_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
