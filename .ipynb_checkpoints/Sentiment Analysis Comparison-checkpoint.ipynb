{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f0/1d9bfcc8ee6b83472ec571406bd0dd51c0e6330ff1a51b2d29861d389e85/textblob-0.15.3-py2.py3-none-any.whl (636kB)\n",
      "\u001b[K    100% |████████████████████████████████| 645kB 17.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: nltk>=3.1 in /anaconda3/lib/python3.7/site-packages (from textblob) (3.4)\n",
      "Requirement already satisfied, skipping upgrade: six in /anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: singledispatch in /anaconda3/lib/python3.7/site-packages (from nltk>=3.1->textblob) (3.4.0.3)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/abz/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import re\n",
    "import html\n",
    "import os.path\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='neg', p_pos=0.462121212121212, p_neg=0.537878787878788)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(\"test test\", analyzer=NaiveBayesAnalyzer()).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = './Data/Stocktwit Raw_preprocessed.csv'\n",
    "file_location_raw = './Data/Stocktwit Raw.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = pd.read_csv(file_location, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothing can get this over . Maybe buyout will...</td>\n",
       "      <td>Sep 17th, 8:40 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Aug Calls] up + . Alerted at on Aug : AM Pea...</td>\n",
       "      <td>Sep 17th, 8:28 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peak profit for the last expired option alerts...</td>\n",
       "      <td>Sep 17th, 8:26 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last six months, option alerts peaked above p...</td>\n",
       "      <td>Sep 17th, 8:25 am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>down. Not looking good for Tuesday. Fed will ...</td>\n",
       "      <td>Sep 17th, 8:11 am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message           datetime\n",
       "0   nothing can get this over . Maybe buyout will...  Sep 17th, 8:40 am\n",
       "1   [Aug Calls] up + . Alerted at on Aug : AM Pea...  Sep 17th, 8:28 am\n",
       "2  Peak profit for the last expired option alerts...  Sep 17th, 8:26 am\n",
       "3   Last six months, option alerts peaked above p...  Sep 17th, 8:25 am\n",
       "4   down. Not looking good for Tuesday. Fed will ...  Sep 17th, 8:11 am"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='neg', p_pos=0.11214806822153346, p_neg=0.8878519317784656)\n",
      "Sentiment(classification='neg', p_pos=0.28638306190904067, p_neg=0.7136169380909578)\n",
      "Sentiment(classification='pos', p_pos=0.6302232656151758, p_neg=0.3697767343848223)\n",
      "Sentiment(classification='pos', p_pos=0.571914459889252, p_neg=0.42808554011074645)\n",
      "Sentiment(classification='pos', p_pos=0.8823677136614579, p_neg=0.11763228633853988)\n",
      "Sentiment(classification='pos', p_pos=0.9932817425597105, p_neg=0.006718257440289915)\n",
      "Sentiment(classification='pos', p_pos=0.90253775511246, p_neg=0.09746224488754142)\n",
      "Sentiment(classification='pos', p_pos=0.7166666666666666, p_neg=0.28333333333333344)\n",
      "Sentiment(classification='pos', p_pos=0.6218878971389639, p_neg=0.378112102861038)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(TextBlob(st[\"message\"][x], analyzer=NaiveBayesAnalyzer()).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " nothing can get this over . Maybe buyout will do it. Like tops i guess.\n",
      " [Aug Calls] up + . Alerted at on Aug : AM Peak after alert on \n",
      "Peak profit for the last expired option alerts for . | . | . | . | . | . |\n",
      " Last six months, option alerts peaked above percent after they were posted\n",
      " down. Not looking good for Tuesday. Fed will make it worse. Market Watch: Asian markets slip as tensions remain high after attack on Saudi oil facilities\n",
      " always a solid buy for portfolio. Also, now over followers & gaining, you guys are awesome! ??\n",
      " China says 'vice ministerial' officials will be in Washington for trade talks cnbc.com china s...\n",
      " it's awesome\n",
      " everyone please report All he does is spam every company with technical analysis Videos that arent even analyzing anything just a stupid crappy way to get you views for his pathetic YouTube channel\n",
      " ??\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(st[\"message\"][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_raw = pd.read_csv(file_location_raw, header=0, encoding = 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$DIS nothing can get this over 140. Maybe $AAPL buyout will do it. Like 150 tops i guess.\n",
      "$AAPL [Aug-30 210 Calls] up +30.43 %  Alerted at $4.60  on Aug 13 2019 10:53AM Peak after alert $6.00 on 2019-08-22\n",
      "Peak profit for the last 6 expired option alerts for $AAPL 10.85 % | 104.11 % | 206.25 % | 16.67 % | 91.21 % | 19.65 % |\n",
      "$AAPL Last six months, 41 option alerts peaked above 100 percent after they were posted\n",
      "$AAPL $ROKU $DE $HD $TGT  down. Not looking good for Tuesday. Fed will make it worse. Market Watch: Asian markets slip as tensions remain high after attack on Saudi oil facilities\n",
      "$AMZN $GOOGL $AAPL $VOOG always a solid buy for portfolio. Also, now over 1800 followers & gaining, you guys are awesome! ??\n",
      "$AAPL China says 'vice ministerial' officials will be in Washington for trade talks - cnbc.com/2019/09/17/china-s...\n",
      "$AAPL $NET $SNAP $OXY it's awesome\n",
      "$AAPL everyone please report @ceobrattwatking. All he does is spam every company with technical analysis Videos that arent even analyzing anything just a stupid crappy way to get you views for his pathetic YouTube channel\n",
      "$AAPL ??\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(st_raw[\"st_3SL2gug\"][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7003\n",
      "0.296\n",
      "0.4404\n",
      "0.0\n",
      "-0.8835\n",
      "0.8463\n",
      "0.0\n",
      "0.6249\n",
      "-0.8979\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "for x in range(10):\n",
    "    print(sia.polarity_scores(st_raw['st_3SL2gug'][x])['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='neg', p_pos=0.11214806822153346, p_neg=0.8878519317784656)\n",
      "Sentiment(classification='neg', p_pos=0.28638306190904067, p_neg=0.7136169380909578)\n",
      "Sentiment(classification='pos', p_pos=0.6302232656151758, p_neg=0.3697767343848223)\n",
      "Sentiment(classification='pos', p_pos=0.584922079862267, p_neg=0.41507792013773376)\n",
      "Sentiment(classification='pos', p_pos=0.8823677136614579, p_neg=0.11763228633853988)\n",
      "Sentiment(classification='pos', p_pos=0.9977505057321676, p_neg=0.002249494267831135)\n",
      "Sentiment(classification='pos', p_pos=0.90253775511246, p_neg=0.09746224488754142)\n",
      "Sentiment(classification='pos', p_pos=0.7542405551272175, p_neg=0.24575944487278337)\n",
      "Sentiment(classification='pos', p_pos=0.6218878971389639, p_neg=0.378112102861038)\n",
      "Sentiment(classification='pos', p_pos=0.5, p_neg=0.5)\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(TextBlob(st_raw['st_3SL2gug'][x], analyzer=NaiveBayesAnalyzer()).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/e3/389c2dd8d0e6ca1d8fad11aa4940e8df6909a26a5d954c0eff01f0d78b57/flair-0.4.3-py3-none-any.whl (180kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 9.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sklearn (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: pytest>=3.6.4 in /anaconda3/lib/python3.7/site-packages (from flair) (4.0.2)\n",
      "Collecting segtok>=1.5.7 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
      "Collecting deprecated>=1.2.4 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /anaconda3/lib/python3.7/site-packages (from flair) (0.2.0)\n",
      "Collecting regex (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
      "\u001b[K    100% |████████████████████████████████| 655kB 6.9MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting hyperopt>=0.1.1 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/12/704382c3081df3ae3f9d96fe6afb62efa2fa9749be20c301cd2797fb0b52/hyperopt-0.1.2-py3-none-any.whl (115kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 8.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=2.2.3 in /anaconda3/lib/python3.7/site-packages (from flair) (3.0.2)\n",
      "Collecting mpld3==0.3 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
      "\u001b[K    100% |████████████████████████████████| 798kB 3.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bpemb>=0.2.9 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in /anaconda3/lib/python3.7/site-packages (from flair) (1.24.1)\n",
      "Collecting tabulate (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /anaconda3/lib/python3.7/site-packages (from flair) (4.28.1)\n",
      "Collecting sqlitedict>=1.6.0 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Collecting torch>=1.1.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/88/7640344d841e97b9a1531385caac39d984b2c6f4abd1376e1ce0de3a0933/torch-1.2.0-cp37-none-macosx_10_7_x86_64.whl (59.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 59.9MB 831kB/s ta 0:00:011\n",
      "\u001b[?25hCollecting langdetect (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.0MB 3.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting gensim>=3.4.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/3a/32a1edf4f335eba0873021a7ddb3230f05dedd2b5450960118b402ca0771/gensim-3.8.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.7MB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipython==7.6.1 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n",
      "\u001b[K    100% |████████████████████████████████| 778kB 4.3MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting pytorch-transformers>=1.1.0 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 7.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /anaconda3/lib/python3.7/site-packages (from sklearn->flair) (0.20.1)\n",
      "Requirement already satisfied: py>=1.5.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.7.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (40.6.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (18.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (4.3.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.2.1)\n",
      "Requirement already satisfied: pluggy>=0.7 in /anaconda3/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (0.8.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /anaconda3/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.10.11)\n",
      "Requirement already satisfied: scipy in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.1.0)\n",
      "Requirement already satisfied: future in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.17.1)\n",
      "Collecting pymongo (from hyperopt>=0.1.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/8c/ec46f4aa95515989711a7893e64c30f9d33c58eaccc01f8f37c4513739a2/pymongo-3.9.0-cp37-cp37m-macosx_10_6_intel.whl (378kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 3.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: networkx in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (2.2)\n",
      "Requirement already satisfied: numpy in /anaconda3/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.15.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda3/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.7.5)\n",
      "Collecting sentencepiece (from bpemb>=0.2.9->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/7d/f077c7d6c8dc958207960896b35ca1bbf6128527b8a6d4c4aef862660489/sentencepiece-0.1.83-cp37-cp37m-macosx_10_6_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 4.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from bpemb>=0.2.9->flair) (2.21.0)\n",
      "Collecting smart-open>=1.7.0 (from gensim>=3.4.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/c0/25d19badc495428dec6a4bf7782de617ee0246a9211af75b302a2681dea7/smart_open-1.8.4.tar.gz (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 5.8MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jedi>=0.10 in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.13.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.6.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.3.2)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (2.0.7)\n",
      "Requirement already satisfied: appnope; sys_platform == \"darwin\" in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.1.0)\n",
      "Requirement already satisfied: pygments in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (2.3.1)\n",
      "Requirement already satisfied: pickleshare in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.7.5)\n",
      "Requirement already satisfied: backcall in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.1.0)\n",
      "Requirement already satisfied: decorator in /anaconda3/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.3.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacremoses (from pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/04/b92425ca552116afdb7698fa3f00ca1c975cfd86a847cf132fd813c5d901/sacremoses-0.0.34.tar.gz (859kB)\n",
      "\u001b[K    100% |████████████████████████████████| 860kB 5.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting boto3 (from pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/b0/50b8c1805dc10b32327eb7b90534c3c3b241b2391a625187c7497f88a829/boto3-1.9.233-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 7.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests->bpemb>=0.2.9->flair) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n",
      "Requirement already satisfied: boto>=2.32 in /anaconda3/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /anaconda3/lib/python3.7/site-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.3.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /anaconda3/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /anaconda3/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
      "Requirement already satisfied: click in /anaconda3/lib/python3.7/site-packages (from sacremoses->pytorch-transformers>=1.1.0->flair) (7.0)\n",
      "Collecting joblib (from sacremoses->pytorch-transformers>=1.1.0->flair)\n",
      "  Using cached https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from boto3->pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/8a/1fc3dba0c4923c2a76e1ff0d52b305c44606da63f718d14d3231e21c51b0/s3transfer-0.2.1-py2.py3-none-any.whl (70kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 7.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting botocore<1.13.0,>=1.12.233 (from boto3->pytorch-transformers>=1.1.0->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/14/a3dc6e29ceb7f45bb64bdf144ece5b3657bbfffbf0480a603aae89cd5296/botocore-1.12.233-py2.py3-none-any.whl (5.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.7MB 3.4MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->pytorch-transformers>=1.1.0->flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/83/94/7179c3832a6d45b266ddb2aac329e101367fbdb11f425f13771d27f225bb/jmespath-0.9.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /anaconda3/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.233->boto3->pytorch-transformers>=1.1.0->flair) (0.14)\n",
      "Building wheels for collected packages: sklearn, segtok, regex, mpld3, tabulate, sqlitedict, langdetect, smart-open, sacremoses\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "  Running setup.py bdist_wheel for segtok ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
      "  Running setup.py bdist_wheel for regex ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
      "  Running setup.py bdist_wheel for mpld3 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
      "  Running setup.py bdist_wheel for tabulate ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "  Running setup.py bdist_wheel for sqlitedict ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Running setup.py bdist_wheel for langdetect ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/5f/ea/fb/5b1a947b369724063b2617011f1540c44eb00e28c3d2ca8692\n",
      "  Running setup.py bdist_wheel for sacremoses ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/07/b9/5b/8bd674c23e962fbff34420a9fa7a2c374d591ecadd5bc37684\n",
      "Successfully built sklearn segtok regex mpld3 tabulate sqlitedict langdetect smart-open sacremoses\n",
      "Installing collected packages: sklearn, regex, segtok, deprecated, pymongo, hyperopt, mpld3, jmespath, botocore, s3transfer, boto3, smart-open, gensim, sentencepiece, bpemb, tabulate, sqlitedict, torch, langdetect, ipython, joblib, sacremoses, pytorch-transformers, flair\n",
      "  Found existing installation: torch 1.0.0\n",
      "    Uninstalling torch-1.0.0:\n",
      "      Successfully uninstalled torch-1.0.0\n",
      "  Found existing installation: ipython 7.2.0\n",
      "    Uninstalling ipython-7.2.0:\n",
      "      Successfully uninstalled ipython-7.2.0\n",
      "Successfully installed boto3-1.9.233 botocore-1.12.233 bpemb-0.3.0 deprecated-1.2.6 flair-0.4.3 gensim-3.8.0 hyperopt-0.1.2 ipython-7.6.1 jmespath-0.9.4 joblib-0.13.2 langdetect-1.0.7 mpld3-0.3 pymongo-3.9.0 pytorch-transformers-1.2.0 regex-2019.8.19 s3transfer-0.2.1 sacremoses-0.0.34 segtok-1.5.7 sentencepiece-0.1.83 sklearn-0.0 smart-open-1.8.4 sqlitedict-1.6.0 tabulate-0.8.3 torch-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./Data/twitter_corpus-master/full-corpus.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126404574230740992</td>\n",
       "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126395626979196928</td>\n",
       "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126394830791254016</td>\n",
       "      <td>Tue Oct 18 20:30:50 +0000 2011</td>\n",
       "      <td>I'm a current @Blackberry user, little bit dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126379685453119488</td>\n",
       "      <td>Tue Oct 18 19:30:39 +0000 2011</td>\n",
       "      <td>The 16 strangest things Siri has said so far. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126377656416612353</td>\n",
       "      <td>Tue Oct 18 19:22:35 +0000 2011</td>\n",
       "      <td>Great up close &amp; personal event @Apple tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126373779483004928</td>\n",
       "      <td>Tue Oct 18 19:07:11 +0000 2011</td>\n",
       "      <td>From which companies do you experience the bes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126366353757179904</td>\n",
       "      <td>Tue Oct 18 18:37:41 +0000 2011</td>\n",
       "      <td>Just apply for a job at @Apple, hope they call...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment             TweetId                       TweetDate  \\\n",
       "0  apple  positive  126415614616154112  Tue Oct 18 21:53:25 +0000 2011   \n",
       "1  apple  positive  126404574230740992  Tue Oct 18 21:09:33 +0000 2011   \n",
       "2  apple  positive  126402758403305474  Tue Oct 18 21:02:20 +0000 2011   \n",
       "3  apple  positive  126397179614068736  Tue Oct 18 20:40:10 +0000 2011   \n",
       "4  apple  positive  126395626979196928  Tue Oct 18 20:34:00 +0000 2011   \n",
       "5  apple  positive  126394830791254016  Tue Oct 18 20:30:50 +0000 2011   \n",
       "6  apple  positive  126379685453119488  Tue Oct 18 19:30:39 +0000 2011   \n",
       "7  apple  positive  126377656416612353  Tue Oct 18 19:22:35 +0000 2011   \n",
       "8  apple  positive  126373779483004928  Tue Oct 18 19:07:11 +0000 2011   \n",
       "9  apple  positive  126366353757179904  Tue Oct 18 18:37:41 +0000 2011   \n",
       "\n",
       "                                           TweetText  \n",
       "0  Now all @Apple has to do is get swype on the i...  \n",
       "1  @Apple will be adding more carrier support to ...  \n",
       "2  Hilarious @youtube video - guy does a duet wit...  \n",
       "3  @RIM you made it too easy for me to switch to ...  \n",
       "4  I just realized that the reason I got into twi...  \n",
       "5  I'm a current @Blackberry user, little bit dis...  \n",
       "6  The 16 strangest things Siri has said so far. ...  \n",
       "7  Great up close & personal event @Apple tonight...  \n",
       "8  From which companies do you experience the bes...  \n",
       "9  Just apply for a job at @Apple, hope they call...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6351\n",
      "0.4588\n",
      "-0.3699\n",
      "0.0\n",
      "-0.6496\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "-0.5542\n",
      "0.5106\n"
     ]
    }
   ],
   "source": [
    "for x in range(475,485):\n",
    "    print(sia.polarity_scores(test['TweetText'][x])['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-23 18:56:10,829 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models-v0.4/classy-imdb-en-rnn-cuda%3A0/imdb-v0.4.pt not found in cache, downloading to /var/folders/76/x5w4_hbd06zd9g8rj1tv2bf80000gn/T/tmprnt0vks7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 127042560/1501979561 [04:59<49:21:24, 7738.09B/s] "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e258f15712cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mflair_sentement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'en-sentiment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#include the sentence here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m475\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m485\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/nn.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, model)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mloaded\u001b[0m \u001b[0mtext\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \"\"\"\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/models/text_classification_model.py\u001b[0m in \u001b[0;36m_fetch_model\u001b[0;34m(model_name)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"http\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;31m# File, and it exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/flair/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Close the connection when no data is returned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    489\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1811\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "flair_sentement = flair.models.TextClassifier.load('en-sentiment')\n",
    "\n",
    "#include the sentence here\n",
    "for x in range(475,485):\n",
    "    s = flair.data.Sentence()\n",
    "\n",
    "    flair_sentement.predict(s)\n",
    "    total_sentiment = s.labels\n",
    "    total_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125224588253741056</td>\n",
       "      <td>Sat Oct 15 15:00:43 +0000 2011</td>\n",
       "      <td>#Siri went down for a little while last night....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125223685194915840</td>\n",
       "      <td>Sat Oct 15 14:57:07 +0000 2011</td>\n",
       "      <td>@ford should have teamed up with @Apple instea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125204228967903232</td>\n",
       "      <td>Sat Oct 15 13:39:49 +0000 2011</td>\n",
       "      <td>Installed io5 - fine on ipad but wiped wife's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125202037293064192</td>\n",
       "      <td>Sat Oct 15 13:31:06 +0000 2011</td>\n",
       "      <td>RT @gdcurry: Really @Apple?  What have you don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>apple</td>\n",
       "      <td>negative</td>\n",
       "      <td>125129328446017536</td>\n",
       "      <td>Sat Oct 15 08:42:11 +0000 2011</td>\n",
       "      <td>DAMN YOU !!! @apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126417484017451009</td>\n",
       "      <td>Tue Oct 18 22:00:51 +0000 2011</td>\n",
       "      <td>@Late_Show I would have watched but the folks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126415742177513472</td>\n",
       "      <td>Tue Oct 18 21:53:56 +0000 2011</td>\n",
       "      <td>RT @rdingwell: .@Apple has a record quarter an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126415618625912832</td>\n",
       "      <td>Tue Oct 18 21:53:26 +0000 2011</td>\n",
       "      <td>Hey @apple, androids releasing brand new state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126414657836687362</td>\n",
       "      <td>Tue Oct 18 21:49:37 +0000 2011</td>\n",
       "      <td>.@Apple has a record quarter and because a bun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>apple</td>\n",
       "      <td>neutral</td>\n",
       "      <td>126410146703351808</td>\n",
       "      <td>Tue Oct 18 21:31:42 +0000 2011</td>\n",
       "      <td>@Apple how fun wouldn't it be if it was possib...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Topic Sentiment             TweetId                       TweetDate  \\\n",
       "475  apple  negative  125224588253741056  Sat Oct 15 15:00:43 +0000 2011   \n",
       "476  apple  negative  125223685194915840  Sat Oct 15 14:57:07 +0000 2011   \n",
       "477  apple  negative  125204228967903232  Sat Oct 15 13:39:49 +0000 2011   \n",
       "478  apple  negative  125202037293064192  Sat Oct 15 13:31:06 +0000 2011   \n",
       "479  apple  negative  125129328446017536  Sat Oct 15 08:42:11 +0000 2011   \n",
       "480  apple   neutral  126417484017451009  Tue Oct 18 22:00:51 +0000 2011   \n",
       "481  apple   neutral  126415742177513472  Tue Oct 18 21:53:56 +0000 2011   \n",
       "482  apple   neutral  126415618625912832  Tue Oct 18 21:53:26 +0000 2011   \n",
       "483  apple   neutral  126414657836687362  Tue Oct 18 21:49:37 +0000 2011   \n",
       "484  apple   neutral  126410146703351808  Tue Oct 18 21:31:42 +0000 2011   \n",
       "\n",
       "                                             TweetText  \n",
       "475  #Siri went down for a little while last night....  \n",
       "476  @ford should have teamed up with @Apple instea...  \n",
       "477  Installed io5 - fine on ipad but wiped wife's ...  \n",
       "478  RT @gdcurry: Really @Apple?  What have you don...  \n",
       "479                                DAMN YOU !!! @apple  \n",
       "480  @Late_Show I would have watched but the folks ...  \n",
       "481  RT @rdingwell: .@Apple has a record quarter an...  \n",
       "482  Hey @apple, androids releasing brand new state...  \n",
       "483  .@Apple has a record quarter and because a bun...  \n",
       "484  @Apple how fun wouldn't it be if it was possib...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.iloc[475:485, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a current @Blackberry user, little bit disappointed with it! Should I move to @Android or @Apple @iphone\n"
     ]
    }
   ],
   "source": [
    "print(test['TweetText'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='pos', p_pos=0.8334341591940115, p_neg=0.16656584080598585)\n",
      "Sentiment(classification='pos', p_pos=0.9465776649056847, p_neg=0.05342233509431446)\n",
      "Sentiment(classification='pos', p_pos=0.9039735123839535, p_neg=0.09602648761604454)\n",
      "Sentiment(classification='pos', p_pos=0.8102297749638064, p_neg=0.18977022503619442)\n",
      "Sentiment(classification='pos', p_pos=0.5386791641295602, p_neg=0.4613208358704399)\n",
      "Sentiment(classification='pos', p_pos=0.726886024740699, p_neg=0.2731139752592998)\n",
      "Sentiment(classification='pos', p_pos=0.8279267786826017, p_neg=0.17207322131739838)\n",
      "Sentiment(classification='pos', p_pos=0.8201646203830273, p_neg=0.17983537961697305)\n",
      "Sentiment(classification='pos', p_pos=0.7326715118947468, p_neg=0.26732848810525106)\n",
      "Sentiment(classification='pos', p_pos=0.8165387032516623, p_neg=0.18346129674833808)\n"
     ]
    }
   ],
   "source": [
    "for x in range(475,485):\n",
    "    print(TextBlob(test[\"TweetText\"][x], analyzer=NaiveBayesAnalyzer()).sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycorenlp\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/40/e74eb4fc7906d630b73a84c9ae9d824f694bd4c5a1d727b8e18beadff613/pycorenlp-0.3.0.tar.gz\n",
      "Collecting requests (from pycorenlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 (from requests->pycorenlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/81/b7/cef47224900ca67078ed6e2db51342796007433ad38329558f56a15255f5/urllib3-1.25.5-py2.py3-none-any.whl (125kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->pycorenlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/18/b0/8146a4f8dd402f60744fa380bc73ca47303cccf8b9190fd16a827281eac2/certifi-2019.9.11-py2.py3-none-any.whl (154kB)\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests->pycorenlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Collecting idna<2.9,>=2.5 (from requests->pycorenlp)\n",
      "  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "Installing collected packages: urllib3, certifi, chardet, idna, requests, pycorenlp\n",
      "  Running setup.py install for pycorenlp: started\n",
      "    Running setup.py install for pycorenlp: finished with status 'done'\n",
      "Successfully installed certifi-2019.9.11 chardet-3.0.4 idna-2.8 pycorenlp-0.3.0 requests-2.22.0 urllib3-1.25.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 19.2.2, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pycorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycorenlp\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/40/e74eb4fc7906d630b73a84c9ae9d824f694bd4c5a1d727b8e18beadff613/pycorenlp-0.3.0.tar.gz\n",
      "Requirement already satisfied: requests in /anaconda3/lib/python3.7/site-packages (from pycorenlp) (2.21.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.7/site-packages (from requests->pycorenlp) (2018.11.29)\n",
      "Building wheels for collected packages: pycorenlp\n",
      "  Running setup.py bdist_wheel for pycorenlp ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/abz/Library/Caches/pip/wheels/fb/e9/2f/767a7b5f2e82d587a36143c04a21839b4b14bebfb89410d2d5\n",
      "Successfully built pycorenlp\n",
      "Installing collected packages: pycorenlp\n",
      "Successfully installed pycorenlp-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pycorenlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv('Data/twitter_corpus-master/full-corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>TweetDate</th>\n",
       "      <th>TweetText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126415614616154112</td>\n",
       "      <td>Tue Oct 18 21:53:25 +0000 2011</td>\n",
       "      <td>Now all @Apple has to do is get swype on the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126404574230740992</td>\n",
       "      <td>Tue Oct 18 21:09:33 +0000 2011</td>\n",
       "      <td>@Apple will be adding more carrier support to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126402758403305474</td>\n",
       "      <td>Tue Oct 18 21:02:20 +0000 2011</td>\n",
       "      <td>Hilarious @youtube video - guy does a duet wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126397179614068736</td>\n",
       "      <td>Tue Oct 18 20:40:10 +0000 2011</td>\n",
       "      <td>@RIM you made it too easy for me to switch to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>apple</td>\n",
       "      <td>positive</td>\n",
       "      <td>126395626979196928</td>\n",
       "      <td>Tue Oct 18 20:34:00 +0000 2011</td>\n",
       "      <td>I just realized that the reason I got into twi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic Sentiment             TweetId                       TweetDate  \\\n",
       "0  apple  positive  126415614616154112  Tue Oct 18 21:53:25 +0000 2011   \n",
       "1  apple  positive  126404574230740992  Tue Oct 18 21:09:33 +0000 2011   \n",
       "2  apple  positive  126402758403305474  Tue Oct 18 21:02:20 +0000 2011   \n",
       "3  apple  positive  126397179614068736  Tue Oct 18 20:40:10 +0000 2011   \n",
       "4  apple  positive  126395626979196928  Tue Oct 18 20:34:00 +0000 2011   \n",
       "\n",
       "                                           TweetText  \n",
       "0  Now all @Apple has to do is get swype on the i...  \n",
       "1  @Apple will be adding more carrier support to ...  \n",
       "2  Hilarious @youtube video - guy does a duet wit...  \n",
       "3  @RIM you made it too easy for me to switch to ...  \n",
       "4  I just realized that the reason I got into twi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-607cb79a944d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mlength_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentimentValue\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mlength_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlength_s\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "scores = []\n",
    "for x in data['TweetText']:\n",
    "    res = nlp.annotate(x,\n",
    "                       properties={\n",
    "                           'annotators': 'sentiment',\n",
    "                           'outputFormat': 'json',\n",
    "                           'timeout': 1000,\n",
    "                       })\n",
    "    ss = 0\n",
    "    length_s = 0\n",
    "    for s in res[\"sentences\"]:\n",
    "            ss = ss + int(s[\"sentimentValue\"])\n",
    "            length_s = length_s+1\n",
    "    if (length_s > 0):\n",
    "        score = ss/length_s\n",
    "    if (score < 2):\n",
    "        score_text = 'negative'\n",
    "    elif(score == 2):\n",
    "        score_text = 'neutral'\n",
    "    else: \n",
    "        score_text = 'positive'\n",
    "    \n",
    "    scores.append(score_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "461"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Topic                                                    apple\n",
       "Sentiment                                             negative\n",
       "TweetId                                     125271422431014914\n",
       "TweetDate                       Sat Oct 15 18:06:49 +0000 2011\n",
       "TweetText    remember when people used to say \"flat the fuc...\n",
       "Name: 460, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[460,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3557483731019523\n"
     ]
    }
   ],
   "source": [
    "sentiments = data['Sentiment'][0:460]\n",
    "index = 0\n",
    "correct_counter = 0\n",
    "for x in sentiments:\n",
    "    if x == scores[index]:\n",
    "        correct_counter = correct_counter + 1\n",
    "    \n",
    "print(correct_counter/461)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
